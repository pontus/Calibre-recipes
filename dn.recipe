
__license__   = 'GPL v3'
__copyright__ = '2011, Pontus Freyhult'
'''
dn.se
'''
from calibre.web.feeds.news import BasicNewsRecipe

import re

class DN_se(BasicNewsRecipe):
    title                 = 'Dagens Nyheter'
    __author__            = 'Darko Miletic, fixes by Pontus Freyhult'
    description           = 'Popular swedish news'
    publisher             = 'Dagens Nyheter'
    category              = 'news, politics, Sveden'
    oldest_article        = 2
    delay                 = 1
    max_articles_per_feed = 100
    no_stylesheets        = True
    use_embedded_content  = False
    encoding              = 'utf-8'
    language              = 'sv'
    cover_url		  = 'http://www.dn.se/Images/Logos/dnse-medals.gif'

    conversion_options = {
                          'comment'   : description
                        , 'tags'      : category
                        , 'publisher' : publisher
                        , 'language'  : language
                        }

    def parse_index(self):
        
        soup = self.index_to_soup('http://www.dn.se/')

        classre = re.compile('Standard')
        hre = re.compile('^/')
        d = {}

        sections = {}

        for p in soup("a",{'href': hre, 'class': classre}):
                link = 'http://www.dn.se/%s?rm=print' % str(p['href'][1:]).strip()

                current_section = p['href'][1:1+p['href'][1:].find('/')].title()
                s = str(p.string).strip()
 
                articles = sections.setdefault(current_section,[])

                if p.string and s!='ttp' and  s.find('img') == -1 and not d.has_key(link):
                    d[link] = 1
                    articles.append( {'title': s,
                               'url': link,
                               'date': '2011-01-01',
                               'description': '',
                               'contents': ''})

        ret = []

        for p in ('Chattar', 'Sport', 'Bostad', 'Webbtv'):
            if sections.has_key(p):
                del sections[p]

        for p in sections.keys():
            ret.append((p,sections[p]))
                                           
        
        return ret

    def postprocess_html(self,soup,first):
        
        # Remove these
        for p in soup(lambda tag: tag.has_key('class') and tag['class'] in ('recommend', 
                                                                            'article-addons', 
                                                                            'box-toolbox',
                                                                            'user-opinions opinions-visible',
                                                                            'content-wrap',
                                                                            'block block-share',
                                                                            'block-inline first last',
                                                                            'box-advert clear',
									    'type-account',
									    'login-form',
									    'socialtabs',
									    'article-readmore',
                                                                            'borderless',
                                                                            'hook-recommend')):
            p.extract()


	    


        while soup.a:
            p = soup.a
            s = ''
            if p.contents:
                s = p.contents[0]

            p.replaceWith(s)

        while soup.strong:
            p = soup.strong
            s = ''
            if p.contents:
                s = p.contents[0]

            p.replaceWith(s)


        while soup.h2:
            p = soup.h2
            p.extract()

        while soup.h3:
            p = soup.h3
            p.extract()


        return soup("div",{'id':'article-content'})[0]

    
